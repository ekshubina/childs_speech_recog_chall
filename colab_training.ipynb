{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cb3589",
   "metadata": {},
   "source": [
    "# Child Speech Recognition - Google Colab Training\n",
    "\n",
    "This notebook trains a Whisper-small model on children's speech data using Google Colab's free GPU.\n",
    "\n",
    "**Before starting:**\n",
    "1. Enable GPU: `Runtime` → `Change runtime type` → `T4 GPU`\n",
    "2. Upload data to Google Drive (see instructions below)\n",
    "3. Run cells sequentially\n",
    "\n",
    "**Estimated time:**\n",
    "- Setup: 5 minutes\n",
    "- Quick test: 5-10 minutes  \n",
    "- Full training: 3-6 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92778f36",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/your-username/childs_speech_recog_chall.git\n",
    "%cd childs_speech_recog_chall\n",
    "\n",
    "# Install dependencies (takes ~2 minutes)\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40749e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU and PyTorch installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ WARNING: No GPU detected! Training will be very slow.\")\n",
    "    print(\"Enable GPU: Runtime → Change runtime type → T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf01a48",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive and Link Data\n",
    "\n",
    "**First-time setup:**\n",
    "1. Upload your data to Google Drive:\n",
    "   - `MyDrive/child_speech_data/train_word_transcripts.jsonl`\n",
    "   - `MyDrive/child_speech_data/audio_0/`\n",
    "   - `MyDrive/child_speech_data/audio_1/`\n",
    "   - `MyDrive/child_speech_data/audio_2/`\n",
    "\n",
    "2. Adjust paths in the cell below if your data is in a different location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"✓ Google Drive mounted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create symlinks to your data in Google Drive\n",
    "# Adjust these paths if your data is in a different location\n",
    "DRIVE_DATA_PATH = \"/content/drive/MyDrive/child_speech_data\"\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "!mkdir -p data\n",
    "\n",
    "# Link manifest file\n",
    "!ln -sf {DRIVE_DATA_PATH}/train_word_transcripts.jsonl data/train_word_transcripts.jsonl\n",
    "\n",
    "# Link audio directories\n",
    "!ln -sf {DRIVE_DATA_PATH}/audio_0 data/audio_0\n",
    "!ln -sf {DRIVE_DATA_PATH}/audio_1 data/audio_1\n",
    "!ln -sf {DRIVE_DATA_PATH}/audio_2 data/audio_2\n",
    "\n",
    "# Verify data is accessible\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "manifest_path = Path('data/train_word_transcripts.jsonl')\n",
    "if manifest_path.exists():\n",
    "    with open(manifest_path) as f:\n",
    "        sample_count = sum(1 for _ in f)\n",
    "    print(f\"✓ Found training manifest with {sample_count:,} samples\")\n",
    "else:\n",
    "    print(\"❌ ERROR: Training manifest not found!\")\n",
    "    print(f\"Expected at: {manifest_path.absolute()}\")\n",
    "    print(\"Make sure data is uploaded to Google Drive and paths are correct.\")\n",
    "\n",
    "for audio_dir in ['audio_0', 'audio_1', 'audio_2']:\n",
    "    audio_path = Path(f'data/{audio_dir}')\n",
    "    if audio_path.exists():\n",
    "        file_count = len(list(audio_path.glob('*.flac')))\n",
    "        print(f\"✓ Found data/{audio_dir}/ with {file_count:,} audio files\")\n",
    "    else:\n",
    "        print(f\"❌ ERROR: data/{audio_dir}/ not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab87e4e",
   "metadata": {},
   "source": [
    "## 3. Quick Test (Recommended First Step)\n",
    "\n",
    "Run a quick test on 100 samples to verify everything works before starting full training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test - trains on 100 samples (takes ~5-10 minutes)\n",
    "!python scripts/train.py --config configs/baseline_whisper_small.yaml --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff828c",
   "metadata": {},
   "source": [
    "## 4. Full Training\n",
    "\n",
    "⚠️ **This will take 3-6 hours** depending on GPU speed. Make sure:\n",
    "- You have GPU enabled (Runtime → Change runtime type → T4 GPU)\n",
    "- Your Colab session won't timeout (keep browser open or use Colab Pro)\n",
    "- Checkpoints are saved to Google Drive for persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80903d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup checkpoint directory in Google Drive for persistence\n",
    "CHECKPOINT_DIR = \"/content/drive/MyDrive/child_speech_checkpoints\"\n",
    "!mkdir -p {CHECKPOINT_DIR}\n",
    "\n",
    "# Update config to save checkpoints to Drive\n",
    "# This ensures checkpoints survive if Colab disconnects\n",
    "!sed -i \"s|output_dir: checkpoints/baseline_whisper_small|output_dir: {CHECKPOINT_DIR}/baseline_whisper_small|g\" configs/baseline_whisper_small.yaml\n",
    "\n",
    "print(f\"✓ Checkpoints will be saved to {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start full training\n",
    "!python scripts/train.py --config configs/baseline_whisper_small.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816736c",
   "metadata": {},
   "source": [
    "## 5. Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/baseline_whisper_small\n",
    "\n",
    "# Alternative: View logs directly\n",
    "# !tail -n 50 logs/train_*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6e1f0",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "MODEL_PATH = f\"{CHECKPOINT_DIR}/baseline_whisper_small/final_model\"\n",
    "\n",
    "!python scripts/evaluate.py \\\n",
    "    --model-path {MODEL_PATH} \\\n",
    "    --val-manifest data/val_manifest.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130ebea",
   "metadata": {},
   "source": [
    "## 7. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "!python scripts/predict.py \\\n",
    "    --model-path {MODEL_PATH} \\\n",
    "    --input-jsonl data/test_manifest.jsonl \\\n",
    "    --output-jsonl predictions.jsonl \\\n",
    "    --batch-size 16\n",
    "\n",
    "# Copy predictions to Drive\n",
    "!cp predictions.jsonl /content/drive/MyDrive/predictions.jsonl\n",
    "\n",
    "print(\"✓ Predictions saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd1c54",
   "metadata": {},
   "source": [
    "## 8. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download predictions file to your local machine\n",
    "from google.colab import files\n",
    "files.download('predictions.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d5c02",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Session Timeout\n",
    "If your Colab session disconnects during training:\n",
    "1. Remount Google Drive (Section 2)\n",
    "2. Resume from checkpoint:\n",
    "```python\n",
    "!python scripts/train.py \\\n",
    "    --config configs/baseline_whisper_small.yaml \\\n",
    "    --resume {CHECKPOINT_DIR}/baseline_whisper_small/checkpoint-XXXX\n",
    "```\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "If you get CUDA OOM errors:\n",
    "1. Reduce batch size in config:\n",
    "```python\n",
    "!sed -i 's/batch_size: 12/batch_size: 8/g' configs/baseline_whisper_small.yaml\n",
    "```\n",
    "2. Restart runtime and try again\n",
    "\n",
    "### Slow Training\n",
    "Verify GPU is enabled:\n",
    "```python\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "```\n",
    "\n",
    "### Data Not Found\n",
    "Check your Google Drive paths:\n",
    "```python\n",
    "!ls -lh /content/drive/MyDrive/child_speech_data/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
