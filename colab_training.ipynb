{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cb3589",
   "metadata": {},
   "source": [
    "# Child Speech Recognition - Google Colab Training\n",
    "\n",
    "This notebook trains a Whisper-small model on children's speech data using Google Colab's free GPU.\n",
    "\n",
    "**Before starting:**\n",
    "1. Enable GPU: `Runtime` → `Change runtime type` → `T4 GPU`\n",
    "2. Upload data to Google Drive (see instructions below)\n",
    "3. Run cells sequentially\n",
    "\n",
    "**Estimated time:**\n",
    "- Setup: 5 minutes\n",
    "- Quick test: 5-10 minutes  \n",
    "- Full training: 3-6 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92778f36",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/ekshubina/childs_speech_recog_chall.git\n",
    "%cd childs_speech_recog_chall\n",
    "\n",
    "# Install dependencies (takes ~2 minutes)\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40749e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU and PyTorch installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ WARNING: No GPU detected! Training will be very slow.\")\n",
    "    print(\"Enable GPU: Runtime → Change runtime type → T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf01a48",
   "metadata": {},
   "source": [
    "## 2. Load Data via Bore Tunnel\n",
    "\n",
    "Transfer data from your Mac directly to Colab — no Google Drive needed.\n",
    "\n",
    "**On your Mac, open two terminals:**\n",
    "\n",
    "**Terminal 1** — serve your data directory:\n",
    "```bash\n",
    "cd /path/to/childs_speech_recog_chall/data\n",
    "python3 -m http.server 8080\n",
    "```\n",
    "\n",
    "**Terminal 2** — expose it with bore:\n",
    "```bash\n",
    "bore local 8080 --to bore.pub\n",
    "# Prints: listening at bore.pub:XXXXX  ← copy that port number\n",
    "```\n",
    "\n",
    "Then set `BORE_PORT` in the cell below and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('data'):\n",
    "    !rm -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ← Set your bore port number here\n",
    "BORE_PORT = \"XXXXX\"\n",
    "BORE_URL = f\"http://bore.pub:{BORE_PORT}\"\n",
    "\n",
    "!mkdir -p data\n",
    "\n",
    "# Download zip files from your Mac\n",
    "!wget -q --show-progress \"{BORE_URL}/audio_0.zip\" -O data/audio_0.zip\n",
    "!wget -q --show-progress \"{BORE_URL}/audio_1.zip\" -O data/audio_1.zip\n",
    "!wget -q --show-progress \"{BORE_URL}/audio_2.zip\" -O data/audio_2.zip\n",
    "!wget -q --show-progress \"{BORE_URL}/train_word_transcripts.jsonl\" -O data/train_word_transcripts.jsonl\n",
    "\n",
    "print(\"✓ Downloads complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zip files\n",
    "# Note: assumes each zip extracts to audio_0/, audio_1/, audio_2/ inside data/\n",
    "# Run: !unzip -l data/audio_0.zip | head -5   to check structure if unsure\n",
    "!unzip -q data/audio_0.zip -d data/\n",
    "!unzip -q data/audio_1.zip -d data/\n",
    "!unzip -q data/audio_2.zip -d data/\n",
    "\n",
    "# Free up disk space\n",
    "# !rm data/audio_*.zip\n",
    "\n",
    "# Verify\n",
    "from pathlib import Path\n",
    "\n",
    "manifest_path = Path('data/train_word_transcripts.jsonl')\n",
    "if manifest_path.exists():\n",
    "    with open(manifest_path) as f:\n",
    "        sample_count = sum(1 for _ in f)\n",
    "    print(f\"✓ Found training manifest with {sample_count:,} samples\")\n",
    "else:\n",
    "    print(\"❌ ERROR: Training manifest not found!\")\n",
    "\n",
    "for audio_dir in ['audio_0', 'audio_1', 'audio_2']:\n",
    "    audio_path = Path(f'data/{audio_dir}')\n",
    "    if audio_path.exists():\n",
    "        file_count = len(list(audio_path.glob('**/*.flac')))\n",
    "        print(f\"✓ Found data/{audio_dir}/ with {file_count:,} audio files\")\n",
    "    else:\n",
    "        print(f\"❌ ERROR: data/{audio_dir}/ not found! Check zip structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab87e4e",
   "metadata": {},
   "source": [
    "## 3. Quick Test (Recommended First Step)\n",
    "\n",
    "Run a quick test on 100 samples to verify everything works before starting full training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test - trains on 100 samples (takes ~5-10 minutes)\n",
    "!python scripts/train.py --config configs/baseline_whisper_small.yaml --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff828c",
   "metadata": {},
   "source": [
    "## 4. Full Training\n",
    "\n",
    "⚠️ **This will take 3-6 hours** depending on GPU speed. Make sure:\n",
    "- You have GPU enabled (Runtime → Change runtime type → T4 GPU)\n",
    "- Your Colab session won't timeout (keep browser open or use Colab Pro)\n",
    "- Checkpoints are saved to Google Drive for persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80903d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints are saved locally in Colab's VM storage\n",
    "# ⚠️ They will be lost if the session ends — download them when training is done\n",
    "CHECKPOINT_DIR = \"/content/childs_speech_recog_chall/checkpoints\"\n",
    "\n",
    "print(f\"✓ Checkpoints will be saved to {CHECKPOINT_DIR}\")\n",
    "print(\"⚠️  Remember to download checkpoints before your session ends!\")\n",
    "print(\"    Use: files.download() or copy back via bore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start full training\n",
    "!python scripts/train.py --config configs/baseline_whisper_small.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816736c",
   "metadata": {},
   "source": [
    "## 5. Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/baseline_whisper_small\n",
    "\n",
    "# Alternative: View logs directly\n",
    "# !tail -n 50 logs/train_*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6e1f0",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "MODEL_PATH = f\"{CHECKPOINT_DIR}/baseline_whisper_small/final_model\"\n",
    "\n",
    "!python scripts/evaluate.py \\\n",
    "    --model-path {MODEL_PATH} \\\n",
    "    --val-manifest data/val_manifest.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130ebea",
   "metadata": {},
   "source": [
    "## 7. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "!python scripts/predict.py \\\n",
    "    --model-path {MODEL_PATH} \\\n",
    "    --input-jsonl data/test_manifest.jsonl \\\n",
    "    --output-jsonl predictions.jsonl \\\n",
    "    --batch-size 16\n",
    "\n",
    "# Copy predictions to Drive\n",
    "!cp predictions.jsonl /content/drive/MyDrive/predictions.jsonl\n",
    "\n",
    "print(\"✓ Predictions saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd1c54",
   "metadata": {},
   "source": [
    "## 8. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download predictions file to your local machine\n",
    "from google.colab import files\n",
    "files.download('predictions.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d5c02",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Session Timeout\n",
    "If your Colab session disconnects during training:\n",
    "1. Re-run cells 1–2 to set up the environment and re-download data\n",
    "2. Resume from the last checkpoint:\n",
    "```python\n",
    "!python scripts/train.py \\\n",
    "    --config configs/baseline_whisper_small.yaml \\\n",
    "    --resume checkpoints/baseline_whisper_small/checkpoint-XXXX\n",
    "```\n",
    "\n",
    "### Bore connection drops / download stalls\n",
    "Restart bore on your Mac and re-run the download cell with the new port.\n",
    "\n",
    "### Wrong zip structure\n",
    "Check what's inside your zip before extracting:\n",
    "```python\n",
    "!unzip -l data/audio_part_0.zip | head -10\n",
    "```\n",
    "If files are at root level (not inside `audio_0/`), extract to the specific folder:\n",
    "```python\n",
    "!unzip -q data/audio_part_0.zip -d data/audio_0/\n",
    "```\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "If you get CUDA OOM errors, reduce batch size:\n",
    "```python\n",
    "!sed -i 's/batch_size: 12/batch_size: 8/g' configs/baseline_whisper_small.yaml\n",
    "```\n",
    "Then restart runtime and try again.\n",
    "\n",
    "### Slow Training\n",
    "Verify GPU is enabled:\n",
    "```python\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "```\n",
    "\n",
    "### Save checkpoints before session ends\n",
    "```python\n",
    "from google.colab import files\n",
    "import shutil\n",
    "shutil.make_archive('checkpoints', 'zip', 'checkpoints/')\n",
    "files.download('checkpoints.zip')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
