{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cb3589",
   "metadata": {},
   "source": [
    "# Child Speech Recognition - Google Colab Training\n",
    "\n",
    "This notebook trains a Whisper-small model on children's speech data using Google Colab's free GPU.\n",
    "\n",
    "**Before starting:**\n",
    "1. Enable GPU: `Runtime` → `Change runtime type` → `T4 GPU`\n",
    "2. Upload data to Google Drive (see instructions below)\n",
    "3. Run cells sequentially\n",
    "\n",
    "**Estimated time:**\n",
    "- Setup: 5 minutes\n",
    "- Quick test: 5-10 minutes  \n",
    "- Full training: 3-6 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92778f36",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/ekshubina/childs_speech_recog_chall.git\n",
    "%cd childs_speech_recog_chall\n",
    "\n",
    "# Install dependencies (takes ~2 minutes)\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Set PYTHONPATH so 'src' module is importable in subprocesses\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = '/content/childs_speech_recog_chall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40749e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU and PyTorch installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ WARNING: No GPU detected! Training will be very slow.\")\n",
    "    print(\"Enable GPU: Runtime → Change runtime type → T4 GPU\")\n",
    "\n",
    "# Verify src module is importable\n",
    "try:\n",
    "    from src.utils.config import load_config\n",
    "    print(\"✓ src module loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ ERROR: Cannot import src module: {e}\")\n",
    "    print(\"Re-run the setup cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f9e8b",
   "metadata": {},
   "source": [
    "### Update Code from Git\n",
    "\n",
    "Run this cell if you've pushed changes to GitHub and need to update the code in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa16a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/childs_speech_recog_chall\n",
    "!git pull origin main\n",
    "\n",
    "# Reinstall requirements if dependencies changed\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"✓ Code updated from GitHub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf01a48",
   "metadata": {},
   "source": [
    "## 2. Load Data via Bore Tunnel\n",
    "\n",
    "Transfer data from your Mac directly to Colab — no Google Drive needed.\n",
    "\n",
    "**On your Mac, open two terminals:**\n",
    "\n",
    "**Terminal 1** — serve your data directory:\n",
    "```bash\n",
    "cd /path/to/childs_speech_recog_chall/data\n",
    "python3 -m http.server 8080\n",
    "```\n",
    "\n",
    "**Terminal 2** — expose it with bore:\n",
    "```bash\n",
    "bore local 8080 --to bore.pub\n",
    "# Prints: listening at bore.pub:XXXXX  ← copy that port number\n",
    "```\n",
    "\n",
    "Then set `BORE_PORT` in the cell below and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('data'):\n",
    "    !rm -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ← Set your bore port number here\n",
    "BORE_PORT = \"XXXXX\"\n",
    "BORE_URL = f\"http://bore.pub:{BORE_PORT}\"\n",
    "\n",
    "!mkdir -p data\n",
    "\n",
    "# Download zip files from your Mac\n",
    "!wget -q --show-progress \"{BORE_URL}/audio_0.zip\" -O data/audio_0.zip\n",
    "!wget -q --show-progress \"{BORE_URL}/audio_1.zip\" -O data/audio_1.zip\n",
    "!wget -q --show-progress \"{BORE_URL}/audio_2.zip\" -O data/audio_2.zip\n",
    "!wget -q --show-progress \"{BORE_URL}/train_word_transcripts.jsonl\" -O data/train_word_transcripts.jsonl\n",
    "\n",
    "print(\"✓ Downloads complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zip files\n",
    "# Note: assumes each zip extracts to audio_0/, audio_1/, audio_2/ inside data/\n",
    "# Run: !unzip -l data/audio_0.zip | head -5   to check structure if unsure\n",
    "!unzip -q data/audio_0.zip -d data/\n",
    "!unzip -q data/audio_1.zip -d data/\n",
    "!unzip -q data/audio_2.zip -d data/\n",
    "\n",
    "# Free up disk space\n",
    "# !rm data/audio_*.zip\n",
    "\n",
    "# Verify\n",
    "from pathlib import Path\n",
    "\n",
    "manifest_path = Path('data/train_word_transcripts.jsonl')\n",
    "if manifest_path.exists():\n",
    "    with open(manifest_path) as f:\n",
    "        sample_count = sum(1 for _ in f)\n",
    "    print(f\"✓ Found training manifest with {sample_count:,} samples\")\n",
    "else:\n",
    "    print(\"❌ ERROR: Training manifest not found!\")\n",
    "\n",
    "for audio_dir in ['audio_0', 'audio_1', 'audio_2']:\n",
    "    audio_path = Path(f'data/{audio_dir}')\n",
    "    if audio_path.exists():\n",
    "        file_count = len(list(audio_path.glob('**/*.flac')))\n",
    "        print(f\"✓ Found data/{audio_dir}/ with {file_count:,} audio files\")\n",
    "    else:\n",
    "        print(f\"❌ ERROR: data/{audio_dir}/ not found! Check zip structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6ef8c",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive\n",
    "\n",
    "Checkpoints are saved locally during training (fast I/O), then copied to Drive afterwards.  \n",
    "**Run this before the quick test and full training.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c904d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and prepare config\n",
    "# Checkpoints are written locally during training, then copied to Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, yaml\n",
    "\n",
    "# Local (fast) storage — used during training\n",
    "LOCAL_CHECKPOINT_DIR = \"/content/childs_speech_recog_chall/checkpoints\"\n",
    "\n",
    "# Google Drive destination\n",
    "DRIVE_CHECKPOINT_DIR = \"/content/drive/MyDrive/childs_speech_recog_chall/checkpoints\"\n",
    "\n",
    "os.makedirs(LOCAL_CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(DRIVE_CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Write a patched config that redirects checkpoints to local storage.\n",
    "# Both the quick test and full training use this same config.\n",
    "RUN_NAME       = \"baseline_whisper_small\"\n",
    "config_patched = \"configs/baseline_whisper_small_local.yaml\"\n",
    "\n",
    "with open(\"configs/baseline_whisper_small.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "local_output = f\"{LOCAL_CHECKPOINT_DIR}/{RUN_NAME}\"\n",
    "cfg[\"training\"][\"output_dir\"]  = local_output\n",
    "cfg[\"training\"][\"logging_dir\"] = f\"{local_output}/runs\"\n",
    "\n",
    "with open(config_patched, \"w\") as f:\n",
    "    yaml.dump(cfg, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(f\"✓ Drive mounted\")\n",
    "print(f\"✓ Checkpoints during training → {local_output}\")\n",
    "print(f\"✓ After training, copy to Drive → {DRIVE_CHECKPOINT_DIR}/{RUN_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab87e4e",
   "metadata": {},
   "source": [
    "## 4. Quick Test (Recommended First Step)\n",
    "\n",
    "Run a quick test on 100 samples to verify everything works before starting full training.  \n",
    "After it finishes, run the **\"Copy to Drive\"** cell to confirm files appear on Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Quick test — trains on 100 samples to verify the pipeline (~5-10 min)\n",
    "!python scripts/train.py --config {config_patched} --debug\n",
    "\n",
    "# Automatically copy to Drive when done\n",
    "local_output = f\"{LOCAL_CHECKPOINT_DIR}/{RUN_NAME}\"\n",
    "drive_output = f\"{DRIVE_CHECKPOINT_DIR}/{RUN_NAME}\"\n",
    "\n",
    "if Path(local_output).exists():\n",
    "    print(\"\\nCopying checkpoints to Google Drive...\")\n",
    "    if Path(drive_output).exists():\n",
    "        shutil.rmtree(drive_output)\n",
    "    shutil.copytree(local_output, drive_output)\n",
    "    print(f\"✓ Saved to Drive: MyDrive/childs_speech_recog_chall/checkpoints/{RUN_NAME}/\")\n",
    "    print(f\"   Files: {[p.name for p in sorted(Path(drive_output).iterdir())]}\")\n",
    "else:\n",
    "    print(\"⚠️ Training did not produce checkpoints — check logs above for errors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff828c",
   "metadata": {},
   "source": [
    "## 5. Full Training\n",
    "\n",
    "⚠️ **This will take 3-6 hours** depending on GPU speed. Make sure:\n",
    "- You have GPU enabled (Runtime → Change runtime type → T4 GPU)\n",
    "- Your Colab session won't timeout (keep browser open or use Colab Pro)\n",
    "- Run the **\"Copy to Drive\"** cell immediately after training finishes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80903d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Drive setup is ready (variables set in the Drive setup cell after data extraction)\n",
    "try:\n",
    "    print(f\"✓ LOCAL_CHECKPOINT_DIR : {LOCAL_CHECKPOINT_DIR}\")\n",
    "    print(f\"✓ DRIVE_CHECKPOINT_DIR : {DRIVE_CHECKPOINT_DIR}\")\n",
    "    print(f\"✓ config_patched       : {config_patched}\")\n",
    "except NameError:\n",
    "    print(\"❌ Drive setup variables not found — re-run the Drive setup cell above (in Section 2)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Full training — uses patched config created in cell 12\n",
    "!python scripts/train.py --config {config_patched}\n",
    "\n",
    "# Automatically copy to Drive when done\n",
    "local_output = f\"{LOCAL_CHECKPOINT_DIR}/{RUN_NAME}\"\n",
    "drive_output = f\"{DRIVE_CHECKPOINT_DIR}/{RUN_NAME}\"\n",
    "\n",
    "if Path(local_output).exists():\n",
    "    print(\"\\nCopying checkpoints to Google Drive...\")\n",
    "    if Path(drive_output).exists():\n",
    "        shutil.rmtree(drive_output)\n",
    "    shutil.copytree(local_output, drive_output)\n",
    "    print(f\"✓ Saved to Drive: MyDrive/childs_speech_recog_chall/checkpoints/{RUN_NAME}/\")\n",
    "    print(f\"   Files: {[p.name for p in sorted(Path(drive_output).iterdir())]}\")\n",
    "else:\n",
    "    print(\"⚠️ Training did not produce checkpoints — check logs above for errors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58af397",
   "metadata": {},
   "source": [
    "### Manual Copy to Drive (fallback only)\n",
    "\n",
    "Checkpoints are copied automatically at the end of each training cell.  \n",
    "Only run this if the automatic copy failed (e.g. training was interrupted).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ── Copy checkpoints to Google Drive ──────────────────────────────────────\n",
    "# Run this cell right after training finishes.\n",
    "# You can also re-run it independently at any time while the session is alive.\n",
    "\n",
    "RUN_NAME     = \"baseline_whisper_small\"\n",
    "local_output = f\"{LOCAL_CHECKPOINT_DIR}/{RUN_NAME}\"\n",
    "drive_output = f\"{DRIVE_CHECKPOINT_DIR}/{RUN_NAME}\"\n",
    "\n",
    "if not Path(local_output).exists():\n",
    "    print(f\"❌ Local checkpoint dir not found: {local_output}\")\n",
    "    print(\"   Training may not have completed yet — check the cell above.\")\n",
    "else:\n",
    "    print(f\"Copying {local_output}  →  {drive_output} ...\")\n",
    "    if Path(drive_output).exists():\n",
    "        shutil.rmtree(drive_output)\n",
    "    shutil.copytree(local_output, drive_output)\n",
    "    print(f\"✓ Done! Files on Drive:\")\n",
    "\n",
    "    for p in sorted(Path(drive_output).rglob(\"*\"))[:30]:\n",
    "        print(f\"   {p.relative_to(drive_output)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816736c",
   "metadata": {},
   "source": [
    "## 6. Monitor Training with TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard — reads from local logs while training, Drive logs after copy\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOCAL_CHECKPOINT_DIR}/baseline_whisper_small/runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6e1f0",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set — uses model from Google Drive\n",
    "MODEL_PATH = f\"{DRIVE_CHECKPOINT_DIR}/baseline_whisper_small/final_model\"\n",
    "\n",
    "!python scripts/evaluate.py \\\n",
    "    --model-path {MODEL_PATH} \\\n",
    "    --val-manifest data/val_manifest.jsonl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130ebea",
   "metadata": {},
   "source": [
    "## 8. Generate Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "!python scripts/predict.py \\\n",
    "    --model-path {MODEL_PATH} \\\n",
    "    --input-jsonl data/test_manifest.jsonl \\\n",
    "    --output-jsonl predictions.jsonl \\\n",
    "    --batch-size 16\n",
    "\n",
    "# Copy predictions to Drive\n",
    "!cp predictions.jsonl /content/drive/MyDrive/predictions.jsonl\n",
    "\n",
    "print(\"✓ Predictions saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd1c54",
   "metadata": {},
   "source": [
    "## 9. Download Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download predictions file to your local machine\n",
    "from google.colab import files\n",
    "files.download('predictions.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d5c02",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### No `childs_speech_recog_chall` folder on Google Drive\n",
    "The folder is created and files are copied by the **\"Copy to Drive\"** cell (the one after training). If it didn't run (training crashed, session timed out, etc.):\n",
    "1. Re-run the setup cell (cell 14) to remount Drive and recreate `LOCAL_CHECKPOINT_DIR` / `DRIVE_CHECKPOINT_DIR` variables\n",
    "2. If local checkpoints still exist (`/content/childs_speech_recog_chall/checkpoints/`), re-run just the **\"Copy to Drive\"** cell\n",
    "3. If local checkpoints are gone too (session restarted), resume from the last checkpoint already on Drive — see below\n",
    "\n",
    "### Session Timeout During Training\n",
    "If your Colab session disconnects **before the \"Copy to Drive\" cell completes**, the local checkpoints are lost.  \n",
    "Resume from the last checkpoint that was already copied to Drive:\n",
    "```python\n",
    "RESUME_CKPT = \"/content/drive/MyDrive/childs_speech_recog_chall/checkpoints/baseline_whisper_small/checkpoint-XXXX\"\n",
    "!python scripts/train.py \\\n",
    "    --config configs/baseline_whisper_small_local.yaml \\\n",
    "    --resume {RESUME_CKPT}\n",
    "```\n",
    "Then re-run the **\"Copy to Drive\"** cell.\n",
    "\n",
    "### Bore connection drops / download stalls\n",
    "Restart bore on your Mac and re-run the download cell with the new port.\n",
    "\n",
    "### Wrong zip structure\n",
    "Check what's inside your zip before extracting:\n",
    "```python\n",
    "!unzip -l data/audio_part_0.zip | head -10\n",
    "```\n",
    "If files are at root level (not inside `audio_0/`), extract to the specific folder:\n",
    "```python\n",
    "!unzip -q data/audio_part_0.zip -d data/audio_0/\n",
    "```\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "If you get CUDA OOM errors, reduce batch size:\n",
    "```python\n",
    "!sed -i 's/batch_size: 12/batch_size: 8/g' configs/baseline_whisper_small.yaml\n",
    "```\n",
    "Then restart runtime and try again.\n",
    "\n",
    "### Slow Training\n",
    "Verify GPU is enabled:\n",
    "```python\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
