{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "77cb3589",
      "metadata": {
        "id": "77cb3589"
      },
      "source": [
        "# Child Speech Recognition - Google Colab Training\n",
        "\n",
        "This notebook trains a Whisper-small model on children's speech data using Google Colab's free GPU.\n",
        "\n",
        "**Before starting:**\n",
        "1. Enable GPU: `Runtime` → `Change runtime type` → `T4 GPU`\n",
        "2. Upload data to Google Drive (see instructions below)\n",
        "3. Run cells sequentially\n",
        "\n",
        "**Estimated time:**\n",
        "- Setup: 5 minutes\n",
        "- Quick test: 5-10 minutes  \n",
        "- Full training: 3-6 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92778f36",
      "metadata": {
        "id": "92778f36"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "83bb5a53",
      "metadata": {
        "id": "83bb5a53",
        "outputId": "a167ec4d-54b1-4e5c-e947-1983eaecbe1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'childs_speech_recog_chall'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 107 (delta 28), reused 107 (delta 28), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (107/107), 146.65 KiB | 9.17 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "/content/childs_speech_recog_chall\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/ekshubina/childs_speech_recog_chall.git\n",
        "%cd childs_speech_recog_chall\n",
        "\n",
        "# Install dependencies (takes ~2 minutes)\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "40749e5b",
      "metadata": {
        "id": "40749e5b",
        "outputId": "5027169a-fb8e-437e-85a4-c52822d5f576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu128\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.64 GB\n"
          ]
        }
      ],
      "source": [
        "# Verify GPU and PyTorch installation\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠️ WARNING: No GPU detected! Training will be very slow.\")\n",
        "    print(\"Enable GPU: Runtime → Change runtime type → T4 GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf01a48",
      "metadata": {
        "id": "6cf01a48"
      },
      "source": [
        "## 2. Mount Google Drive and Link Data\n",
        "\n",
        "**First-time setup:**\n",
        "1. Upload your data to Google Drive:\n",
        "   - `MyDrive/child_speech_data/train_word_transcripts.jsonl`\n",
        "   - `MyDrive/child_speech_data/audio_0/`\n",
        "   - `MyDrive/child_speech_data/audio_1/`\n",
        "   - `MyDrive/child_speech_data/audio_2/`\n",
        "\n",
        "2. Adjust paths in the cell below if your data is in a different location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9379e576",
      "metadata": {
        "id": "9379e576"
      },
      "outputs": [],
      "source": [
        "# Create symlinks to your data in Google Drive\n",
        "# Adjust these paths if your data is in a different location\n",
        "DRIVE_DATA_PATH = \"/content/drive/MyDrive/child_speech_data\"\n",
        "\n",
        "# Create data directory if it doesn't exist\n",
        "!mkdir -p data\n",
        "\n",
        "# Link manifest file\n",
        "!ln -sf {DRIVE_DATA_PATH}/train_word_transcripts.jsonl data/train_word_transcripts.jsonl\n",
        "\n",
        "# Link audio directories\n",
        "!ln -sf {DRIVE_DATA_PATH}/audio_0 data/audio_0\n",
        "!ln -sf {DRIVE_DATA_PATH}/audio_1 data/audio_1\n",
        "!ln -sf {DRIVE_DATA_PATH}/audio_2 data/audio_2\n",
        "\n",
        "# Verify data is accessible\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "manifest_path = Path('data/train_word_transcripts.jsonl')\n",
        "if manifest_path.exists():\n",
        "    with open(manifest_path) as f:\n",
        "        sample_count = sum(1 for _ in f)\n",
        "    print(f\"✓ Found training manifest with {sample_count:,} samples\")\n",
        "else:\n",
        "    print(\"❌ ERROR: Training manifest not found!\")\n",
        "    print(f\"Expected at: {manifest_path.absolute()}\")\n",
        "    print(\"Make sure data is uploaded to Google Drive and paths are correct.\")\n",
        "\n",
        "for audio_dir in ['audio_0', 'audio_1', 'audio_2']:\n",
        "    audio_path = Path(f'data/{audio_dir}')\n",
        "    if audio_path.exists():\n",
        "        file_count = len(list(audio_path.glob('*.flac')))\n",
        "        print(f\"✓ Found data/{audio_dir}/ with {file_count:,} audio files\")\n",
        "    else:\n",
        "        print(f\"❌ ERROR: data/{audio_dir}/ not found!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cab87e4e",
      "metadata": {
        "id": "cab87e4e"
      },
      "source": [
        "## 3. Quick Test (Recommended First Step)\n",
        "\n",
        "Run a quick test on 100 samples to verify everything works before starting full training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a9c59d8",
      "metadata": {
        "id": "5a9c59d8"
      },
      "outputs": [],
      "source": [
        "# Quick test - trains on 100 samples (takes ~5-10 minutes)\n",
        "!python scripts/train.py --config configs/baseline_whisper_small.yaml --debug"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4ff828c",
      "metadata": {
        "id": "a4ff828c"
      },
      "source": [
        "## 4. Full Training\n",
        "\n",
        "⚠️ **This will take 3-6 hours** depending on GPU speed. Make sure:\n",
        "- You have GPU enabled (Runtime → Change runtime type → T4 GPU)\n",
        "- Your Colab session won't timeout (keep browser open or use Colab Pro)\n",
        "- Checkpoints are saved to Google Drive for persistence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e80903d5",
      "metadata": {
        "id": "e80903d5"
      },
      "outputs": [],
      "source": [
        "# Setup checkpoint directory in Google Drive for persistence\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/child_speech_checkpoints\"\n",
        "!mkdir -p {CHECKPOINT_DIR}\n",
        "\n",
        "# Update config to save checkpoints to Drive\n",
        "# This ensures checkpoints survive if Colab disconnects\n",
        "!sed -i \"s|output_dir: checkpoints/baseline_whisper_small|output_dir: {CHECKPOINT_DIR}/baseline_whisper_small|g\" configs/baseline_whisper_small.yaml\n",
        "\n",
        "print(f\"✓ Checkpoints will be saved to {CHECKPOINT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e009889b",
      "metadata": {
        "id": "e009889b"
      },
      "outputs": [],
      "source": [
        "# Start full training\n",
        "!python scripts/train.py --config configs/baseline_whisper_small.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e816736c",
      "metadata": {
        "id": "e816736c"
      },
      "source": [
        "## 5. Monitor Training with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfd68fe",
      "metadata": {
        "id": "4bfd68fe"
      },
      "outputs": [],
      "source": [
        "# Load TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/baseline_whisper_small\n",
        "\n",
        "# Alternative: View logs directly\n",
        "# !tail -n 50 logs/train_*.log"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f6e1f0",
      "metadata": {
        "id": "48f6e1f0"
      },
      "source": [
        "## 6. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c6592e",
      "metadata": {
        "id": "a5c6592e"
      },
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "MODEL_PATH = f\"{CHECKPOINT_DIR}/baseline_whisper_small/final_model\"\n",
        "\n",
        "!python scripts/evaluate.py \\\n",
        "    --model-path {MODEL_PATH} \\\n",
        "    --val-manifest data/val_manifest.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e130ebea",
      "metadata": {
        "id": "e130ebea"
      },
      "source": [
        "## 7. Generate Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e51cb1f5",
      "metadata": {
        "id": "e51cb1f5"
      },
      "outputs": [],
      "source": [
        "# Generate predictions on test set\n",
        "!python scripts/predict.py \\\n",
        "    --model-path {MODEL_PATH} \\\n",
        "    --input-jsonl data/test_manifest.jsonl \\\n",
        "    --output-jsonl predictions.jsonl \\\n",
        "    --batch-size 16\n",
        "\n",
        "# Copy predictions to Drive\n",
        "!cp predictions.jsonl /content/drive/MyDrive/predictions.jsonl\n",
        "\n",
        "print(\"✓ Predictions saved to Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ddd1c54",
      "metadata": {
        "id": "7ddd1c54"
      },
      "source": [
        "## 8. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec7d7ff",
      "metadata": {
        "id": "bec7d7ff"
      },
      "outputs": [],
      "source": [
        "# Download predictions file to your local machine\n",
        "from google.colab import files\n",
        "files.download('predictions.jsonl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e34d5c02",
      "metadata": {
        "id": "e34d5c02"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Session Timeout\n",
        "If your Colab session disconnects during training:\n",
        "1. Remount Google Drive (Section 2)\n",
        "2. Resume from checkpoint:\n",
        "```python\n",
        "!python scripts/train.py \\\n",
        "    --config configs/baseline_whisper_small.yaml \\\n",
        "    --resume {CHECKPOINT_DIR}/baseline_whisper_small/checkpoint-XXXX\n",
        "```\n",
        "\n",
        "### Out of Memory (OOM)\n",
        "If you get CUDA OOM errors:\n",
        "1. Reduce batch size in config:\n",
        "```python\n",
        "!sed -i 's/batch_size: 12/batch_size: 8/g' configs/baseline_whisper_small.yaml\n",
        "```\n",
        "2. Restart runtime and try again\n",
        "\n",
        "### Slow Training\n",
        "Verify GPU is enabled:\n",
        "```python\n",
        "import torch\n",
        "print(torch.cuda.is_available())  # Should be True\n",
        "```\n",
        "\n",
        "### Data Not Found\n",
        "Check your Google Drive paths:\n",
        "```python\n",
        "!ls -lh /content/drive/MyDrive/child_speech_data/\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}