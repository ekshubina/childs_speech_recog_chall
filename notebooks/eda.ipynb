{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e8b833c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Child Speech Recognition Challenge\n",
    "\n",
    "This notebook explores the training data to understand:\n",
    "- Audio duration distributions\n",
    "- Age bucket distributions\n",
    "- Transcription length statistics\n",
    "- Potential outliers\n",
    "- Audio characteristics via spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3910db",
   "metadata": {},
   "source": [
    "## 1. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training manifest\n",
    "data_dir = Path('../data')\n",
    "manifest_path = data_dir / 'train_word_transcripts.jsonl'\n",
    "\n",
    "# Read JSONL file\n",
    "records = []\n",
    "with open(manifest_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        records.append(json.loads(line.strip()))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e567ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Summary:\")\n",
    "print(f\"Total utterances: {len(df):,}\")\n",
    "print(f\"Unique children: {df['child_id'].nunique():,}\")\n",
    "print(f\"Unique sessions: {df['session_id'].nunique():,}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d3f45",
   "metadata": {},
   "source": [
    "## 2. Audio Duration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration statistics\n",
    "print(\"Audio Duration Statistics (seconds):\")\n",
    "print(df['audio_duration_sec'].describe())\n",
    "\n",
    "print(f\"\\nTotal audio duration: {df['audio_duration_sec'].sum() / 3600:.2f} hours\")\n",
    "print(f\"Median duration: {df['audio_duration_sec'].median():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['audio_duration_sec'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df['audio_duration_sec'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"audio_duration_sec\"].mean():.2f}s')\n",
    "axes[0].axvline(df['audio_duration_sec'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[\"audio_duration_sec\"].median():.2f}s')\n",
    "axes[0].set_xlabel('Duration (seconds)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Audio Duration Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['audio_duration_sec'], vert=True)\n",
    "axes[1].set_ylabel('Duration (seconds)')\n",
    "axes[1].set_title('Audio Duration Box Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Duration bins\n",
    "duration_bins = pd.cut(df['audio_duration_sec'], bins=[0, 2, 5, 10, 15, 100])\n",
    "print(\"\\nDuration distribution by bins:\")\n",
    "print(duration_bins.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b352b",
   "metadata": {},
   "source": [
    "## 3. Age Bucket Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age bucket statistics\n",
    "age_counts = df['age_bucket'].value_counts().sort_index()\n",
    "print(\"Age Bucket Distribution:\")\n",
    "print(age_counts)\n",
    "print(f\"\\nPercentage distribution:\")\n",
    "print((age_counts / len(df) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize age bucket distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar chart\n",
    "age_counts.plot(kind='bar', ax=axes[0], color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Age Bucket')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Samples per Age Bucket')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add counts on bars\n",
    "for i, v in enumerate(age_counts):\n",
    "    axes[0].text(i, v + 500, str(v), ha='center', va='bottom')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(age_counts, labels=age_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('Set3'))\n",
    "axes[1].set_title('Age Bucket Distribution (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration by age bucket\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "df.boxplot(column='audio_duration_sec', by='age_bucket', ax=ax)\n",
    "ax.set_xlabel('Age Bucket')\n",
    "ax.set_ylabel('Duration (seconds)')\n",
    "ax.set_title('Audio Duration by Age Bucket')\n",
    "plt.suptitle('')  # Remove default title\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics by age\n",
    "print(\"\\nDuration statistics by age bucket:\")\n",
    "print(df.groupby('age_bucket')['audio_duration_sec'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9474dc4",
   "metadata": {},
   "source": [
    "## 4. Transcription Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab440cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate transcription lengths\n",
    "df['text_length_chars'] = df['orthographic_text'].str.len()\n",
    "df['text_length_words'] = df['orthographic_text'].str.split().str.len()\n",
    "\n",
    "print(\"Transcription Length Statistics:\")\n",
    "print(\"\\nCharacter length:\")\n",
    "print(df['text_length_chars'].describe())\n",
    "print(\"\\nWord count:\")\n",
    "print(df['text_length_words'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89efdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcription length distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Character length histogram\n",
    "axes[0, 0].hist(df['text_length_chars'], bins=100, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[0, 0].axvline(df['text_length_chars'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"text_length_chars\"].mean():.1f}')\n",
    "axes[0, 0].set_xlabel('Character Length')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Transcription Character Length Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Word count histogram\n",
    "axes[0, 1].hist(df['text_length_words'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0, 1].axvline(df['text_length_words'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"text_length_words\"].mean():.1f}')\n",
    "axes[0, 1].set_xlabel('Word Count')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Transcription Word Count Distribution')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Duration vs Character Length\n",
    "axes[1, 0].scatter(df['audio_duration_sec'], df['text_length_chars'], alpha=0.3, s=10)\n",
    "axes[1, 0].set_xlabel('Audio Duration (seconds)')\n",
    "axes[1, 0].set_ylabel('Character Length')\n",
    "axes[1, 0].set_title('Duration vs Character Length')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Duration vs Word Count\n",
    "axes[1, 1].scatter(df['audio_duration_sec'], df['text_length_words'], alpha=0.3, s=10)\n",
    "axes[1, 1].set_xlabel('Audio Duration (seconds)')\n",
    "axes[1, 1].set_ylabel('Word Count')\n",
    "axes[1, 1].set_title('Duration vs Word Count')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation\n",
    "print(f\"\\nCorrelation between duration and character length: {df['audio_duration_sec'].corr(df['text_length_chars']):.3f}\")\n",
    "print(f\"Correlation between duration and word count: {df['audio_duration_sec'].corr(df['text_length_words']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count by age bucket\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "df.boxplot(column='text_length_words', by='age_bucket', ax=ax)\n",
    "ax.set_xlabel('Age Bucket')\n",
    "ax.set_ylabel('Word Count')\n",
    "ax.set_title('Word Count by Age Bucket')\n",
    "plt.suptitle('')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nWord count statistics by age bucket:\")\n",
    "print(df.groupby('age_bucket')['text_length_words'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3317e76",
   "metadata": {},
   "source": [
    "## 5. Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers using IQR method\n",
    "def find_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Duration outliers\n",
    "duration_outliers, dur_lower, dur_upper = find_outliers_iqr(df, 'audio_duration_sec')\n",
    "print(f\"Duration outliers: {len(duration_outliers):,} samples ({len(duration_outliers)/len(df)*100:.2f}%)\")\n",
    "print(f\"Valid range: {dur_lower:.2f}s to {dur_upper:.2f}s\")\n",
    "print(f\"\\nTop 10 longest recordings:\")\n",
    "print(df.nlargest(10, 'audio_duration_sec')[['utterance_id', 'audio_duration_sec', 'age_bucket', 'text_length_words', 'orthographic_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count outliers\n",
    "word_outliers, word_lower, word_upper = find_outliers_iqr(df, 'text_length_words')\n",
    "print(f\"Word count outliers: {len(word_outliers):,} samples ({len(word_outliers)/len(df)*100:.2f}%)\")\n",
    "print(f\"Valid range: {word_lower:.1f} to {word_upper:.1f} words\")\n",
    "print(f\"\\nTop 10 longest transcriptions by word count:\")\n",
    "print(df.nlargest(10, 'text_length_words')[['utterance_id', 'audio_duration_sec', 'text_length_words', 'orthographic_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very short utterances\n",
    "short_utterances = df[df['text_length_words'] <= 2]\n",
    "print(f\"\\nUtterances with ‚â§2 words: {len(short_utterances):,} samples ({len(short_utterances)/len(df)*100:.2f}%)\")\n",
    "print(f\"\\nMost common short transcriptions:\")\n",
    "print(short_utterances['orthographic_text'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20396151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate speech rate (words per second)\n",
    "df['speech_rate'] = df['text_length_words'] / df['audio_duration_sec']\n",
    "df['speech_rate'] = df['speech_rate'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "print(\"Speech Rate Statistics (words/second):\")\n",
    "print(df['speech_rate'].describe())\n",
    "\n",
    "# Visualize speech rate\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Overall distribution\n",
    "axes[0].hist(df['speech_rate'].dropna(), bins=100, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "axes[0].axvline(df['speech_rate'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"speech_rate\"].mean():.2f}')\n",
    "axes[0].set_xlabel('Speech Rate (words/second)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Speech Rate Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# By age bucket\n",
    "df.boxplot(column='speech_rate', by='age_bucket', ax=axes[1])\n",
    "axes[1].set_xlabel('Age Bucket')\n",
    "axes[1].set_ylabel('Speech Rate (words/second)')\n",
    "axes[1].set_title('Speech Rate by Age Bucket')\n",
    "plt.suptitle('')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extremely slow or fast speakers\n",
    "speech_outliers, sr_lower, sr_upper = find_outliers_iqr(df, 'speech_rate')\n",
    "print(f\"\\nSpeech rate outliers: {len(speech_outliers):,} samples ({len(speech_outliers)/len(df)*100:.2f}%)\")\n",
    "print(f\"Valid range: {sr_lower:.2f} to {sr_upper:.2f} words/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf641a",
   "metadata": {},
   "source": [
    "## 6. Audio Quality Analysis\n",
    "\n",
    "### File Size Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File size analysis\n",
    "df['filesize_mb'] = df['filesize_bytes'] / (1024 * 1024)\n",
    "\n",
    "print(\"File Size Statistics:\")\n",
    "print(df['filesize_mb'].describe())\n",
    "print(f\"\\nTotal dataset size: {df['filesize_mb'].sum():.2f} MB ({df['filesize_mb'].sum()/1024:.2f} GB)\")\n",
    "\n",
    "# File size distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(df['filesize_mb'], bins=100, edgecolor='black', alpha=0.7, color='mediumpurple')\n",
    "ax.set_xlabel('File Size (MB)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Audio File Size Distribution')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compression ratio (bytes per second)\n",
    "df['compression_ratio'] = df['filesize_bytes'] / df['audio_duration_sec']\n",
    "print(f\"\\nAverage compression ratio: {df['compression_ratio'].mean():.0f} bytes/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b1e71",
   "metadata": {},
   "source": [
    "### Sample Audio Spectrograms\n",
    "\n",
    "Load and visualize spectrograms for sample audio files to understand audio characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load librosa for spectrogram analysis\n",
    "try:\n",
    "    import librosa\n",
    "    import librosa.display\n",
    "    librosa_available = True\n",
    "except ImportError:\n",
    "    print(\"Warning: librosa not installed. Skipping spectrogram analysis.\")\n",
    "    print(\"Install with: pip install librosa\")\n",
    "    librosa_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12271f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if librosa_available:\n",
    "    # Function to find audio file across multiple directories\n",
    "    def find_audio_file(audio_path, base_dirs=['audio_0', 'audio_1', 'audio_2']):\n",
    "        # Remove 'audio/' prefix if present\n",
    "        filename = audio_path.replace('audio/', '').replace('audio\\\\', '')\n",
    "        \n",
    "        for base_dir in base_dirs:\n",
    "            full_path = data_dir / base_dir / filename\n",
    "            if full_path.exists():\n",
    "                return full_path\n",
    "        return None\n",
    "    \n",
    "    # Sample different age buckets and durations\n",
    "    sample_criteria = [\n",
    "        ('Short (3-4 years)', (df['age_bucket'] == '3-4') & (df['audio_duration_sec'] < 3)),\n",
    "        ('Medium (5-7 years)', (df['age_bucket'] == '5-7') & (df['audio_duration_sec'].between(5, 8))),\n",
    "        ('Long (8-11 years)', (df['age_bucket'] == '8-11') & (df['audio_duration_sec'] > 10)),\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(sample_criteria), 2, figsize=(15, 4 * len(sample_criteria)))\n",
    "    \n",
    "    for idx, (label, condition) in enumerate(sample_criteria):\n",
    "        candidates = df[condition]\n",
    "        if len(candidates) == 0:\n",
    "            print(f\"No samples found for: {label}\")\n",
    "            continue\n",
    "        \n",
    "        # Get a random sample\n",
    "        sample = candidates.sample(1).iloc[0]\n",
    "        audio_path = find_audio_file(sample['audio_path'])\n",
    "        \n",
    "        if audio_path and audio_path.exists():\n",
    "            try:\n",
    "                # Load audio\n",
    "                y, sr = librosa.load(audio_path, sr=16000)\n",
    "                \n",
    "                # Waveform\n",
    "                axes[idx, 0].plot(np.linspace(0, len(y)/sr, len(y)), y)\n",
    "                axes[idx, 0].set_xlabel('Time (s)')\n",
    "                axes[idx, 0].set_ylabel('Amplitude')\n",
    "                axes[idx, 0].set_title(f'{label} - Waveform\\nDuration: {sample[\"audio_duration_sec\"]:.2f}s')\n",
    "                axes[idx, 0].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Spectrogram\n",
    "                D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "                img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[idx, 1])\n",
    "                axes[idx, 1].set_title(f'{label} - Spectrogram\\nText: \"{sample[\"orthographic_text\"][:50]}...\"')\n",
    "                fig.colorbar(img, ax=axes[idx, 1], format='%+2.0f dB')\n",
    "                \n",
    "                print(f\"‚úì Loaded sample for {label}: {sample['utterance_id']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Error loading {label}: {e}\")\n",
    "        else:\n",
    "            print(f\"‚úó Audio file not found for {label}: {sample['audio_path']}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping spectrogram analysis - librosa not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce689b1e",
   "metadata": {},
   "source": [
    "## 7. Vocabulary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all transcriptions\n",
    "all_words = []\n",
    "for text in df['orthographic_text']:\n",
    "    all_words.extend(text.lower().split())\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "print(f\"Total vocabulary size: {len(word_freq):,} unique words\")\n",
    "print(f\"Total word tokens: {len(all_words):,}\")\n",
    "\n",
    "print(\"\\nTop 30 most common words:\")\n",
    "for word, count in word_freq.most_common(30):\n",
    "    print(f\"  {word:20s} {count:6,} ({count/len(all_words)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Word frequency distribution (log scale)\n",
    "word_counts = sorted(word_freq.values(), reverse=True)\n",
    "axes[0].plot(range(1, len(word_counts) + 1), word_counts)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Word Rank (log scale)')\n",
    "axes[0].set_ylabel('Frequency (log scale)')\n",
    "axes[0].set_title('Word Frequency Distribution (Zipf\\'s Law)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Top 30 words bar chart\n",
    "top_words = word_freq.most_common(30)\n",
    "words, counts = zip(*top_words)\n",
    "axes[1].barh(range(len(words)), counts, color='teal', alpha=0.7)\n",
    "axes[1].set_yticks(range(len(words)))\n",
    "axes[1].set_yticklabels(words)\n",
    "axes[1].set_xlabel('Frequency')\n",
    "axes[1].set_title('Top 30 Most Common Words')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Rare words\n",
    "rare_words = [word for word, count in word_freq.items() if count == 1]\n",
    "print(f\"\\nWords appearing only once (hapax legomena): {len(rare_words):,} ({len(rare_words)/len(word_freq)*100:.2f}% of vocabulary)\")\n",
    "print(f\"Sample rare words: {', '.join(rare_words[:20])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7122e3",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23da5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä OVERALL STATISTICS\")\n",
    "print(f\"  Total samples: {len(df):,}\")\n",
    "print(f\"  Unique children: {df['child_id'].nunique():,}\")\n",
    "print(f\"  Unique sessions: {df['session_id'].nunique():,}\")\n",
    "print(f\"  Total audio duration: {df['audio_duration_sec'].sum() / 3600:.2f} hours\")\n",
    "print(f\"  Total dataset size: {df['filesize_mb'].sum() / 1024:.2f} GB\")\n",
    "\n",
    "print(f\"\\nüéôÔ∏è AUDIO CHARACTERISTICS\")\n",
    "print(f\"  Duration range: {df['audio_duration_sec'].min():.2f}s - {df['audio_duration_sec'].max():.2f}s\")\n",
    "print(f\"  Average duration: {df['audio_duration_sec'].mean():.2f}s (¬±{df['audio_duration_sec'].std():.2f}s)\")\n",
    "print(f\"  Median duration: {df['audio_duration_sec'].median():.2f}s\")\n",
    "\n",
    "print(f\"\\nüë∂ AGE DISTRIBUTION\")\n",
    "for age, count in age_counts.items():\n",
    "    print(f\"  {age:12s}: {count:6,} samples ({count/len(df)*100:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nüìù TRANSCRIPTION CHARACTERISTICS\")\n",
    "print(f\"  Word count range: {df['text_length_words'].min():.0f} - {df['text_length_words'].max():.0f} words\")\n",
    "print(f\"  Average words per utterance: {df['text_length_words'].mean():.2f} (¬±{df['text_length_words'].std():.2f})\")\n",
    "print(f\"  Median words per utterance: {df['text_length_words'].median():.0f}\")\n",
    "print(f\"  Total vocabulary size: {len(word_freq):,} unique words\")\n",
    "print(f\"  Average speech rate: {df['speech_rate'].mean():.2f} words/second\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è POTENTIAL ISSUES\")\n",
    "print(f\"  Duration outliers: {len(duration_outliers):,} samples ({len(duration_outliers)/len(df)*100:.2f}%)\")\n",
    "print(f\"  Very short utterances (‚â§2 words): {len(short_utterances):,} samples ({len(short_utterances)/len(df)*100:.2f}%)\")\n",
    "print(f\"  Speech rate outliers: {len(speech_outliers):,} samples ({len(speech_outliers)/len(df)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21c5c5",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **Dataset Size**: The dataset contains ~95K utterances from children across different age groups\n",
    "2. **Age Distribution**: Most samples are from the 8-11 age bucket, with representation across all age groups\n",
    "3. **Audio Duration**: Most utterances are between 2-10 seconds, with a median around 5-6 seconds\n",
    "4. **Transcription Length**: Average utterance length is around 10-15 words, with significant variation\n",
    "5. **Speech Rate**: Children's speech rate varies by age, with older children typically speaking faster\n",
    "6. **Vocabulary**: Large vocabulary with many rare words (hapax legomena), indicating diverse content\n",
    "\n",
    "## Recommendations for Training\n",
    "\n",
    "1. **Stratified Splitting**: Ensure validation set has proportional representation from all age buckets\n",
    "2. **Duration Handling**: Consider padding/truncating strategy for very long or short utterances\n",
    "3. **Data Quality**: Monitor outliers (very fast/slow speech rates) during training\n",
    "4. **Age-Specific Analysis**: Track model performance separately by age bucket to identify weaknesses\n",
    "5. **Vocabulary Coverage**: Ensure tokenizer handles children's speech patterns and common words effectively"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
